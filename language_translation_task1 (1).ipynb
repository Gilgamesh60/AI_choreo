{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c222bd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c222bd7",
        "outputId": "5167471d-9cd4-4501-cc72-311e2f311fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-12 16:29:37.929947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-06-12 16:29:53.354354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "Unique tokens in source (de) vocabulary: 5374\n",
            "Unique tokens in target (en) vocabulary: 4556\n",
            "German -  zwei junge weiße männer sind im freien in der nähe vieler büsche .  Length -  13\n",
            "English -  two young , white males are outside near many bushes .  Length -  11\n",
            "\n",
            "German -  mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .  Length -  8\n",
            "English -  several men in hard hats are operating a giant pulley system .  Length -  12\n",
            "\n",
            "German -  ein kleines mädchen klettert in ein spielhaus aus holz .  Length -  10\n",
            "English -  a little girl climbing into a wooden playhouse .  Length -  9\n",
            "\n",
            "German -  ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster .  Length -  15\n",
            "English -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n",
            "\n",
            "German -  zwei männer stehen am herd und bereiten essen zu .  Length -  10\n",
            "English -  two men are at the stove preparing food .  Length -  9\n",
            "\n",
            "German -  ein mann in grün hält eine gitarre , während der andere mann sein hemd ansieht .  Length -  16\n",
            "English -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n",
            "\n",
            "German -  ein mann lächelt einen ausgestopften löwen an .  Length -  8\n",
            "English -  a man is smiling at a stuffed lion  Length -  8\n",
            "\n",
            "German -  ein schickes mädchen spricht mit dem handy während sie langsam die straße entlangschwebt .  Length -  14\n",
            "English -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n",
            "\n",
            "German -  eine frau mit einer großen geldbörse geht an einem tor vorbei .  Length -  12\n",
            "English -  a woman with a large purse is walking by a gate .  Length -  12\n",
            "\n",
            "German -  jungen tanzen mitten in der nacht auf pfosten .  Length -  9\n",
            "English -  boys dancing on poles in the middle of the night .  Length -  11\n",
            "\n",
            "Maximum Length of English Sentence 41 and German Sentence 44 in the dataset\n",
            "Minimum Length of English Sentence 4 and German Sentence 1 in the dataset\n",
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(5374, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            ")\n",
            "DecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(4556, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",
            ")\n",
            "Seq2Seq(\n",
            "  (Encoder_LSTM): EncoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(5374, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  )\n",
            "  (Decoder_LSTM): DecoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(4556, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "    (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch - 1 / 1\n",
            "Epoch_Loss - 3.3655357360839844\n",
            "\n",
            "3.639220130745868\n"
          ]
        }
      ],
      "source": [
        "#Data Preparation and pre-processing\n",
        "\n",
        "\n",
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy, random\n",
        "\n",
        "## Loading the SpaCy's vocabulary for our desired languages.\n",
        "!python -m spacy download en_core_web_sm --quiet\n",
        "!python -m spacy download de_core_news_sm --quiet\n",
        "\n",
        "spacy_german = spacy.load(\"de_core_news_sm\")\n",
        "spacy_english = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def tokenize_german(text):\n",
        "    return [token.text for token in spacy_german.tokenizer(text)]\n",
        "\n",
        "def tokenize_english(text):\n",
        "    return [token.text for token in spacy_english.tokenizer(text)]\n",
        "\n",
        "german = Field(tokenize=tokenize_german, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_english, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = (\".de\", \".en\"),\n",
        "                                                    fields=(german, english))\n",
        "\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "\n",
        "print(f\"Unique tokens in source (de) vocabulary: {len(german.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                      batch_size = BATCH_SIZE,\n",
        "                                                                      sort_within_batch=True,\n",
        "                                                                      sort_key=lambda x: len(x.src),\n",
        "                                                                      device = device)\n",
        "\n",
        "max_len_ger=[]\n",
        "max_len_eng=[]\n",
        "count=0\n",
        "\n",
        "# Dataset Sneek peek before tokenizing\n",
        "for data in train_data:\n",
        "    max_len_ger.append(len(data.src))\n",
        "    max_len_eng.append(len(data.trg))\n",
        "    if count < 10 :\n",
        "        print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
        "        print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
        "        print()\n",
        "    count += 1\n",
        "\n",
        "print(\"Maximum Length of English Sentence {} and German Sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n",
        "print(\"Minimum Length of English Sentence {} and German Sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))\n",
        "\n",
        "#Encoder code implementation\n",
        "\n",
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "        self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "    def forward(self, x):\n",
        "\n",
        "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = len(german.vocab)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
        "print(encoder_lstm)\n",
        "\n",
        "#Decoder code implementation\n",
        "\n",
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "        super(DecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "        self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "        self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "    def forward(self, x, hidden_state, cell_state):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "         x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "         embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "         outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "\n",
        "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
        "         predictions = self.fc(outputs)\n",
        "\n",
        "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
        "         predictions = predictions.squeeze(0)\n",
        "\n",
        "         return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(english.vocab)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(english.vocab)\n",
        "\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "print(decoder_lstm)\n",
        "\n",
        "#Seq2Seq (encoder-decoder code implementation)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.Encoder_LSTM = encoder_lstm\n",
        "        self.Decoder_LSTM = decoder_lstm\n",
        "\n",
        "    def forward(self, source, target, tfr=0.5):\n",
        "    # Shape - Source : (10, 32) [(Sentence length German + some padding), Number of Sentences]\n",
        "        batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(english.vocab)\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766)\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "        hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "        x = target[0] # Trigger token <SOS>\n",
        "\n",
        "        for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766)\n",
        "            output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
        "            outputs[i] = output\n",
        "            best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "            x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766)\n",
        "        return outputs\n",
        "\n",
        "model=Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "#Seq2Seq model training\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#from torch.utils import translate_sentence, bleu, load_checkpoint, save_checkpoint\n",
        "\n",
        "load_model=False\n",
        "epoch_loss = 0.0\n",
        "num_epochs = 1\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "sentence1 = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n",
        "ts1 = []\n",
        "step=0\n",
        "learning_rate=0.001\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "model=Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#if load_model:\n",
        "  #load_checkpoint(torch.load('my_checkpoint.pth.ptar', model, optimizer))\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "    model.eval()\n",
        "    #translated_sentence1 = translate_sentence(model, sentence1, german, english, device, max_length=50)\n",
        "    #print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n",
        "    #ts1.append(translated_sentence1)\n",
        "\n",
        "    model.train(True)\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        input = batch.src.to(device)\n",
        "        target = batch.trg.to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "        output = model(input, target)\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "        loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using back propagation\n",
        "        optimizer.step()\n",
        "        step += 1\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_epoch = epoch\n",
        "        #checkpoint={'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\n",
        "        #save_checkpoint(checkpoint)\n",
        "        if ((epoch - best_epoch) >= 10):\n",
        "            print(\"no improvement in 10 epochs, break\")\n",
        "            break\n",
        "    print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "    print()\n",
        "\n",
        "print(epoch_loss / len(train_iterator))\n",
        "\n",
        "#score = bleu(test_data[1:100], model, german, english, device)\n",
        "#print(f\"Bleu score {score*100:.2f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf7d32e",
      "metadata": {
        "id": "dcf7d32e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}